# Biomedical Data Science with Python

## 0. Prelude

- 0.1 Why Python?
- 0.2 Python 2 or 3?
- 0.3 The Jupyter notebook
- 0.4 The Rodeo IDE
- 0.5 Installing and maintaining packages
- 0.6 Virtual environments
- 0.7 Version control and `git`

## 1. The Python language

- 1.1 Writing and executing a Python program
- 1.2 Data types, containers, I/O and control flow
- 1.3 Functions
- 1.4 Classes
- 1.5 Generators and coroutines
- 1.6 Functional core and imperative shell
- 1.7 Decorators
- 1.8 The Python Standard Library
- 1.9 Testing code and continuous integration
- 1.10 Packaging and distribution of Python programs

## 2. The scientific stack

- 2.1 Analysis, modeling, visualization and archival of scientific data
- 2.2 Using `numpy` for numeric processing and linear algebra
- 2.3 Using `scipy` for distributions and special functions
- 2.4 Using `pandas` for tabular data analysis
- 2.5 Using `statsmodels` for statistical modeling
- 2.6 Using `matplotlib` for basic plotting
- 2.7 Using `seaborn` for statistical graphics
- 2.8 Using `h5py` to store hierarchical data
- 2.9 Using Jupyter as a scientific notebook and application

## 3. Web scraping and data cleaning

- 3.1 Open data sources
- 3.2 RESTful APIs
- 3.3 Getting web documents with `requests`
- 3.4 Parsing JSON with `json`
- 3.5 Parsing XML with `xml.etree.ElementTre`
- 3.6 Parsing HTML with `beautifulsoup`
- 3.7 Web scraping with `scrapy`
- 3.8 Using `MongoDB` for document storage

## 4. Machine learning

- 4.1 Dimension reduction
- 4.2 Unsupervised learning
- 4.3 Supervised learning
- 4.4 Feature selection
- 4.5 Evaluation and validation
- 4.6 Workflow and pipelines
- 4.7 Machine learning with `sklearn`
- 4.8 Deep learning with `TensorFlow`
- 4.9 Bayesian machine learning with `pymc3` and `pystan`
- 4.10 Image analysis with OpenCV

## 5. Text processing

- 5.1 Reading and writing text files
- 5.2 Basic string processing
- 5.3 Using regular expressions
- 5.4 Comparing strings with `fuzzywuzzy`
- 5.5 Natural language processing with `nltk`
- 5.6 Using `gensim` for topic modeling
- 5.7 Working with the semantic web with `rdflib`

## 6. Big data and making Python faster

- 6.1 Use better data structures, algorithms and libraries
- 6.2 Generators and the `itertools` Library
- 6.3 Asynchronous and event-driven programming
- 6.4 Simple multicore programming with `multiprocessing` and `deco`
- 6.5 Just-in-time compilation and easy parallelization with `numba`
- 6.6 From Python to Cython
- 6.7 Using `pybind11` to work with C++
- 6.8 Using `fotranmagic` to work with Fortran
- 6.9 Out-of-core data analysis with the Blaze ecosystem
- 6.10 Distributed data programming with `pyspark`
- 6.11 Python as glue: Polyglot programming in Jupyter
