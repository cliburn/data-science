# Foundations of biomedical data science

## Learning objectives

At the end of the course, the student should be able to:

1. Present an overview of the data science discipline
2. State and implement best practices for scientific computing
3. Use the Unix shell for system administration and remote computing
4. Use the ecosystem of data archival systems and formats
5. Perform common data processing tasks in Python
6. Construct queries to retrieve data from SQL and NoSQL databases

## Syllabus

### Week 1 Overview of biomedical data science

- Components of biomedical data science
  - Statistical models
  - Computational skills
  - Biomedical domain knowledge
  - Tools of the trade
    - The Unix shell
    - Text editors and integrated development environments
    - Version control systems
    - Regular expressions
    - Python
    - R
    - SQL and database systems
- The data science workflow
  - Obtaining data
  - Cleaning data
  - Exploring data
  - Modeling data
  - Interpreting data
- Examples of biomedical data science
  - Genomics
  - Electronic health records
  - Medical imaging

### Week 2 Using the Unix shell

- Getting started
  - POSIX
  - The Unix philosophy
  - The Unix shell
  - History and tab completion
  - Getting help
- Basic skills
  - File and directory management
  - Working with text files
  - Pipes and redirection
- Intermediate skills
  - Finding things
  - Regular expressions
  - Remote computing
  - Shell scripting
- Miscellaneous
  - Command line tools for data science
  - Installing software
  - Virtual machines and micro-containers

### Week 3 Using `git`

- Concepts of version control systems
  - Why version control?
  - Examples of version control systems
  - Git concepts
  - Github, Bitbucket and Gitlab
- Using `git` as an individual
  - Initialization
  - Creating a repository
  - Recording changes to files: add, commit
  - Viewing changes: status, diff
  - Undoing changes: checkout, revert, reset
  - Ignoring files
  - Working on the web: clone, pull, push
- Using `git` collaboratively
  - Branching
  - Merging
  - Handling merge conflicts
- Using `GitHub`
  - Development metrics
  - Using `github-pages`
  - Issue tracking
  - Continuous integration

### Week 4 Python: Data types, collections and control flow

- What is Python good for?
  - General purpose computing
  - Glue language
  - Data preprocessing
  - Large data science ecosystem
  - Python implementations
- Environments for Python
  - Jupyter
  - Atom and other text editors
  - Rodeo and other IDEs
- Getting started with Python
  - Data types
  - Collections
  - Built-in functions
  - Loops and control flow
  - Basic I/O
  - Handling exceptions
- The Python ecosystem
  - PEPs and the Python style guidelines
  - The Zen of Python
  - Tour of standard library
  - PyPI (Python Packaging Index)
  - Modules, packages and imports
  - Installing Python packages with `distribute`, `pip` and `conda`

### Week 5 Python: Functions and classes

- Functions
  - Writing custom functions
  - Arguments for functions
  - Nested functions
  - Higher order functions
  - Anonymous functions
  - Using `itertools`, `functools`, `operator` and `toolz`
- Iterators and generators
  - Using `yield`
  - Using `yield from`
  - Using `send`
  - Generator expressions
  - Iterators: dissecting the for loop
- Classes
  - Classes, attributes and methods
  - Base classes
  - Inheritance and derived classes
  - Special methods
  - Properties
- Object-oriented programming
  - SOLID
    - Single responsibility
    - Open-closed
    - Liskov substitution
    - Interface segregation
    - Dependency inversion
  - Classical design patterns

### Week 6 Python: Text and regular expressions

- Working with text files
  - Context managers for opening and closing files
  - File handlers as generators
  - String methods
- Text mining
  - Word count
  - Shifting windows
  - Term frequency and inverse document frequency
  - Topic models
- Regular expression basics
  - Basic matching
  - Flags
  - Capture groups
- Natural language processing
  - Using the `nltk` package
  - Stemming
  - Parsing syntax trees
  - Error correction

### Week 7 Python: Numbers and scientific computing

- Using arrays
  - Creating arrays
  - Indexing
  - Slicing
  - Sorting
  - Broadcasting
  - Concatenation
  - Universal functions
- Using random numbers
  - Drawing samples from distributions
  - Random sampling with and without replacement
  - Running simulations
  - Permutations and combinations
- Linear algebra
  - Vector and matrix operations
  - Norms and distances
  - Inverting and transposing matrices
  - Solving linear systems
  - Eigenvalues and eigenvectors
  - PCA and SVD
- Useful scipy packages
  - `scipy.statistics`
  - `scipy.linalg`
  - `scipy.integrate`
  - `scipy.interpolate`
  - `scipy.optimize`

### Week 8 Getting data

- Using `pandas`
  - Reading CSV and tabular data
  - Reading Excel
  - Reading from SQL database
  - Reading from JSON
  - Reading from HDF5
- Getting data with programmatic APIs
  - Ad hoc APIs
  - Using a REST API (e.g. Twitter streams)
- Basic web scraping
  - Why is web scarping necessary?
  - Using requests` and `beautifulsoup`
- Intermediate web scraping
  - Large-scale scraping with `scrapy`

### Week 9: Data management

- Using `feather` to share data between Python and R
- Using HDF5
  - A self-documenting hierarchical data store
  - Working with groups, arrays and attributes
  - Using `h5py`
- Basic concepts of relational databases
  - Rows, columns and tables
  - Primary and foreign keys
  - Joins
  - Data normalization
  - Data validation
- Using an SQL database (e.g. SQLite3, PostgreSQL)
  - Reading and sorting data
  - Filtering with where
  - Calculating new values on the fly
  - Handling missing values
  - Combining values using aggregation
  - Combining information from multiple tables using join
  - Creating, modifying, and deleting data
- Using a NoSQL database (e.g. MongoDB)

### Week 10 Data cleaning

- Principles of tidy data
  - Every row is an observation
  - Every column is a variable
  - Every table is a data type
- Fixing problems
  - Data validation
  - Fixing naming errors
  - Removing duplicate data
  - Handling missing data
- Basic data munging with `pandas`
  - Getting information about a data frame
  - Indexes and indexing
  - Slicing
  - Sorting
  - Operations on numeric columns
  - Operations on text columns
  - Operations on categorical columns
- From messy to tidy with `pandas`
  - Reshaping with `melt`, `stack` and `unstack`
  - Pivoting data
  - Splitting one column into several
  - Merging data frames

### Week 11 Exploratory data analysis

- Split-apply-combine
  - Using group by operations
  - Aggregation and reduction functions
  - Generating contingency tables
- Imperative plotting with `matplotlib`
  - Types of plots
  - Customizing plots
  - Customizing layouts
  - Saving figures
- Declarative plotting with `seaborn`
  - Grammar of graphics
  - Styles and contexts
  - Single plots
  - Grid plots
  - Colors and other scales
  - Customizing `seaborn` plots
- Interactive plots
  - User interaction with `ipywidgets`
  - Interactive plots with `bokeh`
  - Interactive maps
  - Linked plots

### Week 12 Modeling data with `scikit-learn`

- Working with variables
  - Scaling
  - Normalization
  - Transformations
- Dimension reduction
  - PCA
  - MDS
  - Factor analysis
  - Random projections
- Unsupervised learning
  - Hierarchical Clustering
  - K-means
  - Mixture models
- Statistical learning
  - Classification
  - Regression
  - Feature selection
  - Model evaluation
  - Assembling a pipeline

### Week 13 Reproducible analysis and reporting

- The FAIR principles
  - Findability
  - Accessibility
  - Interoperability
  - Reusability
- Reproducible data
  - Curating data
  - Annotating data
  - Data standards
  - Ontologies
  - Depositing data in biomedical repositories
- Reproducible reports
  - Literate programming
  - Using virtual environments
  - Using Docker
  - Generating reports from Jupyter notebooks
  - Generating `github-pages`  content from JUpyter notebooks
  - Using `make`
- Packaging your code
  - Make it open source
  - Structure of Python packages
  - Providing a test suite
  - Uploading to PyPI so that it is `pip` installable
  - Using `ReadTheDocs`
